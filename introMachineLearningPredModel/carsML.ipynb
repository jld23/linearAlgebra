{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook continues the exercise of predicting car prices based on Craigslist listings.\n",
    "\n",
    "This notebook uses `pandas` and `scikit-learn` two popular Python packages for data science. \n",
    "\n",
    "In order to make the processing more efficient, a sample of the data has been taken.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Here are the packages that need to be loaded to run this example\n",
    "\n",
    "These is where all the needed packages are imported for the exercise. If you get an `ModuleNotFoundError` then install the package (pip or conda) before continuing.These is where all the needed packages are imported for the exercise. If you get an `ModuleNotFoundError` then install the package (pip or conda) before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import feather\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, ElasticNet, Ridge, HuberRegressor, PassiveAggressiveRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code from Introduction to Data Science Exercise\n",
    "\n",
    "This code was used to create the profiles you used in earlier course in this series with the exception that this code is running on a 10% sample instead of the 500k+ listings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Sample Data from CSV to Pandas dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = feather.read_dataframe('../data/vehicles_samp.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print first observations for sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the columns and their respective types for the cars dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create profile of full dataset using `pandas-profile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ProfileReport(cars)\n",
    "prof.to_file(output_file='vehicle_profile.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the data for cars with more than 300,000 miles and sort decending\n",
    "\n",
    "This is an example of how Python programers can chain methods to each other to accomplish multiple tasks in the same line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[cars['odometer']>300000].filter(items=['year','price','odometer','model']).sort_values('odometer', ascending=False).head()\n",
    "#filter(items=['one', 'three'])\n",
    "#,['year','price','odometer','model']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the number of columns\n",
    "\n",
    "With wide datasets it is often hard to see all the columns. The code below is an example of how the columns can be filtered to just those that are desired.\n",
    "\n",
    "As with all things Python, there are many ways to accomplish this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.filter(items=['year','price','odometer','model']).sort_values('odometer', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.filter(items=['year','price','odometer','model']).sort_values('price', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new dataFrame `cars2` \n",
    "\n",
    "`cars2` only includes listings that meet all the following criteria\n",
    "*    newer than 2000\n",
    "*    cost less than $40,000\n",
    "*    have less than 100,000 miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars2 = cars[(cars['year']>2000) & (cars['price']<40000) & (cars['odometer']<100000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the shape of `cars` and `cars2`\n",
    "\n",
    "I want to see how many rows and columns `cars` has and how many were lost due to the `filter` method\n",
    "\n",
    "The data shows a reduction from 540K to 219K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ProfileReport(cars2)\n",
    "prof.to_file(output_file='vehicle_profile2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars2.to_csv('../data/cars2.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars2 = pd.read_csv('../data/cars2.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Modeling and Machine Learning\n",
    "\n",
    "The rest of this notebook is work that should be completed along with the Modeling and Machine Learning course\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for data prep and modeling\n",
    "\n",
    "To make the code more portable and easier to update. In the cell below I will define the inputs and targets.\n",
    "\n",
    "The inputs are the attributes of a car that will be used to predict the price, which is the target.\n",
    "\n",
    "To deal with missing values, there are different treatments for nominal vs interval data. Below lists are defined to identify the type of each variable.\n",
    "\n",
    "The virtue of this type of organization is that to add or subtract a variable from the model, it only requires modifications to this cell and then a rerun of the code below. \n",
    "\n",
    "It also allows more copy/paste from project to projects saving time in the long run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = cars2.drop(columns=['price','id','url','region_url','vin','description','county','image_url'])\n",
    "nominal = ['region', 'manufacturer', 'fuel', 'model','title_status','transmission', 'drive', 'type','paint_color','state']\n",
    "ordinal = ['condition','size','cylinders']\n",
    "interval = ['year','odometer','lat','long']\n",
    "target = cars2.price\n",
    "print(inputs.shape, target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipelines\n",
    "\n",
    "A `pipeline` is a process or set of steps that you want to organize into a specific pattern.\n",
    "\n",
    "In the pipeline below, each variable is imputed based on its type and then scaled to improve model performance (scaling input is a best practice along with spliting data to training and validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, interval),\n",
    "        ('cat', categorical_transformer, nominal),\n",
    "        ('ord', categorical_transformer, ordinal)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and validation (70/30)\n",
    "\n",
    "Another needed step in modeling is to split the data into training and validation. The help protect against a model overfitting and as a result having poor predictions for future cases. \n",
    "\n",
    "People disagree as to the right amount to split between training and validation but assuming I have \"enough\" data, I usually split the data to 70% training and 30% validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_test, target_train, target_test = train_test_split(inputs, target, test_size = 0.30, random_state=9878)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the models\n",
    "\n",
    "In the code below a list of many algorythnms is provided and for each a model is build on the training data. \n",
    "\n",
    "The model is then applied to the validation data and assessment metrics are calculated.\n",
    "\n",
    "The assessment metrics are then printed so that comparisons can be made.\n",
    "\n",
    "**Remember:** there is no single best modeling algorthym so you should try many types and parameterizations based on the business problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a results DataFrame. This code is in a different cell to prevent loss run to run.\n",
    "results_df = pd.DataFrame(columns=('model','r_2','explainedVariance','mse','buildTime','scoreTime'))\n",
    "results_df['r_2'] = results_df['r_2'].map('${:,.4f}'.format)\n",
    "results_df['explainedVariance'] = results_df['explainedVariance'].map('${:,.4f}'.format)\n",
    "results_df['mse'] = results_df['mse'].map('${:,.0f}'.format)\n",
    "results_df['buildTime'] = results_df['buildTime'].map('${:,.1f}'.format)\n",
    "results_df['scoreTime'] = results_df['scoreTime'].map('${:,.1f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: This step could take several minutes to complete**\n",
    "\n",
    "The list of models are all default values of regression or decision trees and their derivatives.\n",
    "\n",
    "We're not training a neural network because for this data it takes over 60 minutes in the binder env.\n",
    "\n",
    "Here is a link to the documentation so that you can [learn more](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# List of models to run\n",
    "model_list = [LinearRegression(), ElasticNet(), Ridge(max_iter=300), HuberRegressor(), PassiveAggressiveRegressor(), DecisionTreeRegressor(), RandomForestRegressor(), GradientBoostingRegressor()]\n",
    "# Removed MLPRegressor() because it was taking 60 minutes to train\n",
    "#model_list = [MLPRegressor(early_stopping=True, hidden_layer_sizes=(3,50))]\n",
    "# LassoLars(), \n",
    "\n",
    "# loop through model list\n",
    "for model in model_list:\n",
    "    build_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)])\n",
    "    ts_build = time.time()\n",
    "    build_model.fit(input_train, target_train)\n",
    "    ts_score = time.time()\n",
    "    target_pred = build_model.predict(input_test)\n",
    "    ts_done = time.time()\n",
    "    results = pd.DataFrame([[model, \n",
    "                build_model.score(input_test, target_test), \n",
    "                explained_variance_score(target_test, target_pred), \n",
    "                mean_squared_error(target_test, target_pred), \n",
    "                ts_score-ts_build, \n",
    "                ts_done-ts_score]], columns=results_df.columns)\n",
    "    # append results to dataFrame\n",
    "    results_df = results_df.append(results, ignore_index=True)\n",
    "\n",
    "    print(\"model score for {}: R_2: {:0.4f} Explained Variance:{:0.4f} MSE:{:0.0f} Build Time(s):{:0.1f} Score Time(s):{:0.1f}\".format(model, build_model.score(input_test, target_test), explained_variance_score(target_test, target_pred), mean_squared_error(target_test, target_pred), ts_score-ts_build, ts_done-ts_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results dataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "\n",
    "Using the Chart above which model is the best if `explainedVariance` is the most important metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Considering all the factors in the table, which model would you choose to deploy? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How do the times to train (`buildTime`) the model compare to the times to score (`scoreTime`) the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "What might be some next steps to take after getting these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 BONUS\n",
    " \n",
    "Can you find a model that has a better explained variance than the default models I provided above?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 5\n",
    "\n",
    "You solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}